{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part 15 - Lesson 2 - Notebook.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OVaGy-Lg9hhr"},"source":["# Part 14 - Lesson 2 - Notebook"]},{"cell_type":"code","metadata":{"id":"XYYDvoskkE61","executionInfo":{"status":"ok","timestamp":1624475081996,"user_tz":240,"elapsed":1628,"user":{"displayName":"Jordan Sauchuk","photoUrl":"","userId":"08387430205938821804"}}},"source":["import json\n","import tensorflow as tf\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"0eJSTTYnkJQd","executionInfo":{"status":"ok","timestamp":1624475083373,"user_tz":240,"elapsed":183,"user":{"displayName":"Jordan Sauchuk","photoUrl":"","userId":"08387430205938821804"}}},"source":["vocab_size = 10000\n","embedding_dim = 16\n","max_length = 100\n","trunc_type='post'\n","padding_type='post'\n","oov_tok = \"<OOV>\"\n","training_size = 20000"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"BQVuQrZNkPn9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624475085844,"user_tz":240,"elapsed":406,"user":{"displayName":"Jordan Sauchuk","photoUrl":"","userId":"08387430205938821804"}},"outputId":"9099d002-e46c-48ea-a394-fa8da9dd0c81"},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n","    -O /tmp/sarcasm.json"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2021-06-23 19:04:45--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 74.125.142.128, 173.194.202.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5643545 (5.4M) [application/json]\n","Saving to: ‘/tmp/sarcasm.json’\n","\n","\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.05s   \n","\n","2021-06-23 19:04:45 (106 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oaLaaqhNkUPd","executionInfo":{"status":"ok","timestamp":1624475088067,"user_tz":240,"elapsed":165,"user":{"displayName":"Jordan Sauchuk","photoUrl":"","userId":"08387430205938821804"}}},"source":["with open(\"/tmp/sarcasm.json\", 'r') as f:\n","    datastore = json.load(f)\n","\n","sentences = []\n","labels = []\n","\n","for item in datastore:\n","    sentences.append(item['headline'])\n","    labels.append(item['is_sarcastic'])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"S1sD-7v0kYWk","executionInfo":{"status":"ok","timestamp":1624475089723,"user_tz":240,"elapsed":170,"user":{"displayName":"Jordan Sauchuk","photoUrl":"","userId":"08387430205938821804"}}},"source":["training_sentences = sentences[0:training_size]\n","testing_sentences = sentences[training_size:]\n","training_labels = labels[0:training_size]\n","testing_labels = labels[training_size:]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3u8UB0MCkZ5N","executionInfo":{"status":"ok","timestamp":1624475092244,"user_tz":240,"elapsed":998,"user":{"displayName":"Jordan Sauchuk","photoUrl":"","userId":"08387430205938821804"}}},"source":["tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n","tokenizer.fit_on_texts(training_sentences)\n","\n","word_index = tokenizer.word_index\n","\n","training_sequences = tokenizer.texts_to_sequences(training_sentences)\n","training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n","testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"FufaT4vlkiDE","executionInfo":{"status":"ok","timestamp":1624475098446,"user_tz":240,"elapsed":5392,"user":{"displayName":"Jordan Sauchuk","photoUrl":"","userId":"08387430205938821804"}}},"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    tf.keras.layers.GlobalAveragePooling1D(),\n","    tf.keras.layers.Dense(24, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfDt1hmYkiys","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624475098446,"user_tz":240,"elapsed":4,"user":{"displayName":"Jordan Sauchuk","photoUrl":"","userId":"08387430205938821804"}},"outputId":"36c3fb80-ea35-4199-dde0-4cd541c1ac5e"},"source":["model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 100, 16)           160000    \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 16)                0         \n","_________________________________________________________________\n","dense (Dense)                (None, 24)                408       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 25        \n","=================================================================\n","Total params: 160,433\n","Trainable params: 160,433\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2DTKQFf1kkyc","colab":{"base_uri":"https://localhost:8080/","height":324},"executionInfo":{"status":"error","timestamp":1624475101408,"user_tz":240,"elapsed":534,"user":{"displayName":"Jordan Sauchuk","photoUrl":"","userId":"08387430205938821804"}},"outputId":"7bf907a7-229a-418d-e1c7-d987aeab0c5f"},"source":["num_epochs = 30\n","history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)"],"execution_count":9,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-809d1d825c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_data_adapter_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     self._adapter = adapter_cls(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 994\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    995\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     raise RuntimeError(\n","\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})"]}]},{"cell_type":"code","metadata":{"id":"2HYfBKXjkmU8"},"source":["import matplotlib.pyplot as plt\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show()\n","\n","plot_graphs(history, \"accuracy\")\n","plot_graphs(history, \"loss\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SBdAZAenvzL"},"source":["reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","\n","def decode_sentence(text):\n","    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n","\n","print(decode_sentence(training_padded[0]))\n","print(training_sentences[2])\n","print(labels[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9MqihtEkzQ9"},"source":["e = model.layers[0]\n","weights = e.get_weights()[0]\n","print(weights.shape) # shape: (vocab_size, embedding_dim)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LoBXVffknldU"},"source":["import io\n","\n","out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n","out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n","for word_num in range(1, vocab_size):\n","  word = reverse_word_index[word_num]\n","  embeddings = weights[word_num]\n","  out_m.write(word + \"\\n\")\n","  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n","out_v.close()\n","out_m.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4eZ5HtVnnEE"},"source":["try:\n","  from google.colab import files\n","except ImportError:\n","  pass\n","else:\n","  files.download('vecs.tsv')\n","  files.download('meta.tsv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cG8-ArY-qDcz"},"source":["sentence = [\"granny starting to fear spiders in the garden might be real\", \"game of thrones season finale showing this sunday night\"]\n","sequences = tokenizer.texts_to_sequences(sentence)\n","padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","print(model.predict(padded))"],"execution_count":null,"outputs":[]}]}